---
title: "Practical Machine Learning Course Project"
author: "Vince Glick"
date: "Monday, May 25, 2015"
output: html_document
---

###The goal of your project is to predict the manner in which they did the exercise. This is the "classe" variable in the training set. You may use any of the other variables to predict with. 

###You should create a report describing:
1. How you built your model, how you used cross validation, 
2. What you think the expected out of sample error is, and why you made the choices you did. 
3. You will also use your prediction model to predict 20 different test cases. 

###Libraries Required
```{r}
library(AppliedPredictiveModeling)
library(caret)
library(rattle)
library(rpart.plot)
library(randomForest)
```

###Data Processing
First it is imperative to isolate all of the values within the training and data sets that contain unnecessary values. After having done so, the next step is to isolate the data frame which contains only those values which gauge the measurement for prediction. In this case, the final will void the first 7 columns.
```{r}
pmltesting<-data.frame(read.csv("pml-testing.csv", na.strings=c("NA","#DIV/0!","")))
pmltesting<-subset(pmltesting, na.strings=c("NA","#DIV/0!",""))
pmltesting<-pmltesting[, colSums(is.na(pmltesting))==0]
pmltesting <- pmltesting[,8:length(colnames(pmltesting))]

pmltrain<-data.frame(read.csv("pml-training.csv", na.strings=c("NA","#DIV/0!","")))
pmltrain<-subset(pmltrain, na.strings=c("NA","#DIV/0!",""))
pmltrain<-pmltrain[, colSums(is.na(pmltrain))==0]
pmltrain <- pmltrain[,8:length(colnames(pmltrain))]
```

###Check for covariates
```{r}
nearZeroVar(pmltrain, saveMetrics=TRUE)
```

Next, we proceed to set a random sample seed for the rest of the process. Here we partition the initial training data into two sets for testing prior to the final. We utilize the 60/40 rule, separating the training and test subsets respectively.
```{r}
set.seed(2)
pmltrain2 <- createDataPartition(pmltrain$classe, p=0.6)[[1]]
pmltrain_training <- pmltrain[pmltrain2,]
pmltrain_testing <- pmltrain[-pmltrain2,]
```

##Classification trees (method = rpart)
Utilizing the decision tree applicaiton, we invoke rpart on the training subset
```{r}
mf <- train(pmltrain_training$classe ~ ., data = pmltrain_training, method="rpart")
print(mf$finalModel, digits=3)
fancyRpartPlot(mf$finalModel)
```

Invoking the prediction function against the testing subset we created from our training set, we utilize the confusion matrix to review the test results.
```{r}
predmf <- predict(mf, newdata=pmltrain_testing)
confusionMatrix(predmf, pmltrain_testing$classe)
```

A review of the results provides us with an Accuracy of 0.5041 with rparts implementation through decision trees.



##Random forests (method = rf)
In order to allow for maximal utilization of the Random forest without unneccessarily overfitting on purpose, we continue to apply the randomForest method without preprocessing.
```{r}
set.seed(2)
mf2<-randomForest(classe ~. , data=pmltrain_training)
print(mf2)
```

Once again, we invoke the prediction function and run a test before the final.
```{r}
predmf2<-predict(mf2,pmltrain_testing)
print(confusionMatrix(predmf2, pmltrain_testing$classe), digits=4)
```


#Final Testing
```{r}
testset=predict(mf2, newdata=pmltesting)
print(testset)
```

#Conclusion
Random Forests yielded a better result, as its 0.9917 Accuracy provides for a stronger yield for prediction amongst subsets within this data.
